rule pcon:
    input:
        "data/{dataset}/{prefix}.fasta"
        
    output:
        bin = "count/{dataset}/pcon/{prefix}.k{kmer_size}.pcon",
        
    log:
        "log/count/pcon/{dataset}_{prefix}.k{kmer_size}.txt"
        
    benchmark:
        "count/bench/pcon/{dataset}_{prefix}.k{kmer_size}.tsv"
        
    resources:
        mem_mb = lambda wcd: pcon_memory_usage(int(wcd.kmer_size))

    threads:
        config['max_threads']
        
    shell:
        "pcon -vvv -t {threads} count -i {input} -o {output.bin} -k {wildcards.kmer_size}  2>&1 > {log}"


rule pcon_cd:
    input:
        "data/{dataset}/{prefix}.fasta"
        
    output:
        bin = "count/{dataset}/pcon_cd/{prefix}.k{kmer_size}.pcon",
        csv = "count/{dataset}/pcon_cd/{prefix}.k{kmer_size}.csv"

    log:
        "log/count/pcon_cd/{dataset}_{prefix}.k{kmer_size}.txt"
        
    benchmark:
        "count/bench/pcon_cd/{dataset}_{prefix}.k{kmer_size}.tsv"
        
    resources:
        mem_mb = lambda wcd: pcon_memory_usage(int(wcd.kmer_size))

    threads:
        config['max_threads']
        
    shell:
        """
        pcon -vvv -t {threads} count -i {input} -o {output.bin} -k {wildcards.kmer_size} 2>&1 > {log}
        pcon -vvv -t {threads} dump -i {output.bin} -c {output.csv} 2>&1 >> {log}
        """
        
rule kmc:
    input:
        "data/{dataset}/{prefix}.fasta"

    output:
        "count/{dataset}/kmc/{prefix}.k{kmer_size}.kmc_suf"

    log:
        "log/count/kmc/{dataset}_{prefix}.k{kmer_size}.txt"
        
    benchmark:
        "count/bench/kmc/{dataset}_{prefix}.k{kmer_size}.tsv"

    params:
        work_dir = lambda wcd: f"tmp/kmc/{wcd.dataset}_{wcd.prefix}_{wcd.kmer_size}",
        kmc_out = lambda wcd: f"count/{wcd.dataset}/kmc/{wcd.prefix}.k{wcd.kmer_size}"

    threads:
        config['max_threads']
        
    conda:
        f"../{config['env_mode']}/kmc.yaml"
        
    shell:
        """
        mkdir -p {params.work_dir}
        kmc -k{wildcards.kmer_size} -t{threads} -r -fa {input} {params.kmc_out} {params.work_dir} 2>&1 > {log}
        """

        
rule kmc_cd:
    input:
        "data/{dataset}/{prefix}.fasta"

    output:
        "count/{dataset}/kmc_cd/{prefix}.k{kmer_size}.csv"

    log:
        "log/count/kmc_cd/{dataset}_{prefix}.k{kmer_size}.txt"
        
    benchmark:
        "count/bench/kmc_cd/{dataset}_{prefix}.k{kmer_size}.tsv"

    params:
        work_dir = lambda wcd: f"tmp/kmc_cd/{wcd.dataset}_{wcd.prefix}_{wcd.kmer_size}",
        kmc_out = lambda wcd: f"count/{wcd.dataset}/kmc_cd/{wcd.prefix}.k{wcd.kmer_size}"

    threads:
        config['max_threads']
        
    conda:
        f"../{config['env_mode']}/kmc.yaml"
        
    shell:
        """
        mkdir -p {params.work_dir}
        kmc -k{wildcards.kmer_size} -t{threads} -r -fa {input} {params.kmc_out} {params.work_dir} 2>&1 > {log}
        kmc_dump {params.kmc_out} {output} 2>&1 >> {log}
        """


rule jellyfish:
    input:
        "data/{dataset}/{prefix}.fasta"
        
    output:
        "count/{dataset}/jellyfish/{prefix}.k{kmer_size}.jf"

    log:
        "log/count/jellyfish/{dataset}_{prefix}.k{kmer_size}.txt"
        
    benchmark:
        "count/bench/jellyfish/{dataset}_{prefix}.k{kmer_size}.tsv"

    threads:
        config['max_threads']
        
    conda:
        f"../{config['env_mode']}/jellyfish.yaml"
        
    shell:
        "jellyfish count -m{wildcards.kmer_size} -t{threads} -s10G -C -o {output} {input} 2>&1 > {log}"

        
rule jellyfish_cd:
    input:
        "data/{dataset}/{prefix}.fasta"
        
    output:
        bin = "count/{dataset}/jellyfish_cd/{prefix}.k{kmer_size}.jf",
        csv = "count/{dataset}/jellyfish_cd/{prefix}.k{kmer_size}.csv"

    log:
        "log/count/jellyfish_cd/{dataset}_{prefix}.k{kmer_size}.txt"
        
    benchmark:
        "count/bench/jellyfish_cd/{dataset}_{prefix}.k{kmer_size}.tsv"

    threads:
        config['max_threads']
        
    conda:
        f"../{config['env_mode']}/jellyfish.yaml"
        
    shell:
        """
        jellyfish count -m{wildcards.kmer_size} -t{threads} -s10G -C -o {output.bin} {input} 2>&1 > {log}
        jellyfish dump -c -o {output.csv} {output.bin} 2>&1 >> {log}
        """

        
rule count_ref:
    input:
        [f"count/bacteria/pcon/reference.k{kmer_size}.pcon" for kmer_size in conf_range("kmer")],
        [f"count/bacteria7/pcon/reference.k{kmer_size}.pcon" for kmer_size in conf_range("kmer")],
        [f"count/bacteria5/pcon/reference.k{kmer_size}.pcon" for kmer_size in conf_range("kmer")],
        [f"count/yeast/pcon/reference.k{kmer_size}.pcon" for kmer_size in conf_range("kmer")],
        [f"count/metagenome/pcon/reference.k{kmer_size}.pcon" for kmer_size in conf_range("kmer")],
        [f"count/celegans/pcon/reference.k{kmer_size}.pcon" for kmer_size in conf_range("kmer")],
        
rule count_all:
    input:
        (count_files(d) for d in config["real_dataset"]),
        (count_files(f"synthetic.e{mean_id}.c{config['coverage']}") for mean_id in conf_range("identity")),
        (count_files(f"celegans.e{config['celegans_identity']}.c{coverage}") for coverage in conf_range("celegans_coverage")),
        rules.count_ref.input,
    
